{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import scipy.signal as signal\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation function\n",
    "def simulate(kk):\n",
    "    matplotlib.use('agg')\n",
    "    SNR = 80\n",
    "    Eo = .4\n",
    "    alpha= .2\n",
    "    tauv = 30\n",
    "    tauo = 2\n",
    "    fs = 100\n",
    "    cutOffFreq = np.linspace(0.001,.7999,10)\n",
    "    # Stimulus Shape. Should be a 6 second stimulus\n",
    "    traps = np.convolve(np.ones(int(2*fs)), np.ones(int(5*fs)))\n",
    "    win = signal.hamming(len(traps))\n",
    "    traps = traps/traps.max()*1#*win\n",
    "    u=np.zeros(int(fs*100*10))\n",
    "    tauv = tauv + np.zeros(len(u))\n",
    "    signs = [0,0]\n",
    "    # Make 20 stimuli of one condition immediately followed by another condition\n",
    "    # which causes an alternate directionality of connectivity\n",
    "    for i in range(20):\n",
    "        if signs[0] >= 10 or signs[1] >= 10:\n",
    "           s = np.argmin(signs)*2-1 \n",
    "        else:\n",
    "            s =  np.sign(np.random.randn())\n",
    "            if s <0:\n",
    "                signs[0] += 1\n",
    "            else:\n",
    "                signs[1] +=1\n",
    "        u[int(fs*10)+i*fs*50:int(fs*10)+i*fs*50 + len(traps)] += s*traps\n",
    "        u[int(2*fs*10)+i*fs*50:int(2*fs*10)+i*fs*50 + len(traps)] += -s*traps\n",
    "    X = np.zeros((len(u),100))\n",
    "    q = np.zeros((len(u),100))\n",
    "    p = np.zeros((len(u),100))\n",
    "    v = np.zeros((len(u),100))\n",
    "    f = np.zeros((len(u),100))\n",
    "    s = np.zeros((len(u),100))\n",
    "    high = .1\n",
    "    low = .01\n",
    "    rHR = (high+low)*np.random.rand(len(u)) +low\n",
    "    h = 1/fs\n",
    "    np.random.seed(kk)\n",
    "    # Bilinear neural state matrices\n",
    "    A1 = .4*(np.random.randn(50,50))\n",
    "    A2 = .4*(np.random.randn(50,50))\n",
    "    A3 = .4*(np.random.randn(50,50))\n",
    "    A4 = .4*(np.random.randn(50,50))\n",
    "    A = np.eye(100)\n",
    "    A[:50,:50] = A1\n",
    "    A[50:,50:] = A3\n",
    "    C = .1*np.random.randn(100,100)\n",
    "    C2 = .1*np.random.randn(100,100)\n",
    "    U2 = 10*np.random.binomial(1,.3,(len(u),100)).astype(float)\n",
    "    U2[:,25:75] *= .1\n",
    "    def dqdvdp(X,Q, V, P,S,F, U,t):\n",
    "        # Vascular parameters\n",
    "        Eo = .4\n",
    "        tauo = 2\n",
    "        tauv = 30\n",
    "        epsilon = .005\n",
    "        taus = .8\n",
    "        tauf = .4\n",
    "        E = 1 - (1 - Eo)**(1/F)\n",
    "        alpha = .4\n",
    "        F = np.log(1 + np.exp(F))\n",
    "\n",
    "        # Diagonal is implicitly diagonal returning to baseline\n",
    "        A = -np.eye(100)*2\n",
    "        # Network self connectivities\n",
    "        A[:50,:50] = A1\n",
    "        A[50:,50:] = A3\n",
    "        UU = U2[t]\n",
    "        # Autonomous, undriven, unforced, linear dynamics\n",
    "        dx = -3*X +UU\n",
    "        # Check condition for which connectivity direction to induce\n",
    "        if U < 0:\n",
    "            A[50:,:50] = 1*A2\n",
    "            U = 1*np.ones(100)*U**2\n",
    "            C[50:] *= 1\n",
    "            U = (U)\n",
    "            dx += (A.dot(X)) +U\n",
    "        elif U > 0:\n",
    "            A[:50,50:] = 1*A4\n",
    "            U = 1*np.ones(100)*U**2\n",
    "            U = (U)\n",
    "            C[:50] *= 1\n",
    "            dx += (A.dot(X)) + U\n",
    "        # Hemodynamic dynamics\n",
    "        df = S\n",
    "        ds = epsilon*X - S/taus - (F-1)/tauf\n",
    "        dq = F/tauo *(E/Eo - Q/V) + 1/tauv*(F - V**(1/alpha))*Q/V\n",
    "        dv = 1/tauv*(F - V**(1/alpha))\n",
    "        dp = 1/tauv*(F - V**(1/alpha))*P/V\n",
    "        return np.vstack((dq, dv, dp, df, ds,dx))\n",
    "    # Initial conditions of each voxel\n",
    "    X[0] = 0*np.ones(100)\n",
    "    q[0] = 1*np.ones(100)\n",
    "    p[0] = 6.4*np.ones(100)\n",
    "    v[0] = 1*np.ones(100)\n",
    "    s[0] = 0*np.ones(100)\n",
    "    f[0] = 1*np.ones(100)\n",
    "    derivf = []\n",
    "    derivs = []\n",
    "    derivv = []\n",
    "    derivp = []\n",
    "    derivq = []\n",
    "    derivx = []\n",
    "    # Adams Bashforth implicit integration FAST!\n",
    "    for i, (y1_t, y2_t, y3_t, y4_t, y5_t,y6_t) in enumerate(zip(q[:-1],v[:-1],p[:-1], s[:-1], f[:-1],X[:-1])):\n",
    "        if i < 4:\n",
    "            k1 = dqdvdp(X[i],q[i], v[i], p[i], s[i], f[i], u[i],i)\n",
    "            ink2 = (y6_t + k1[5]/2, y1_t + k1[0]/2, y2_t + k1[1]/2, y3_t + k1[2]/2,y4_t + k1[3]/2, y5_t + k1[4]/2,)\n",
    "            k2 = dqdvdp(*ink2, u[i],i)\n",
    "            ink3 = (y6_t + k2[5]/2, y1_t + k2[0]/2, y2_t + k2[1]/2, y3_t + k2[2]/2,y4_t + k2[3]/2, y5_t + k2[4]/2,)\n",
    "            k3 = dqdvdp(*ink3, u[i],i)\n",
    "            ink4 = (y6_t + k2[5], y1_t + k3[0], y2_t + k3[1], y3_t + k3[2], y4_t + k3[3], y5_t + k3[4],)\n",
    "            k4 = dqdvdp(*ink4, u[i],i)\n",
    "            derivq.append(1/6*(k1[0] + k2[0]*2 + 2*k3[0] + k4[0]))\n",
    "            derivv.append(1/6*(k1[1] + k2[1]*2 + 2*k3[1] + k4[1]))\n",
    "            derivp.append(1/6*(k1[2] + k2[2]*2 + 2*k3[2] + k4[2]))\n",
    "            derivf.append(1/6*(k1[3] + k2[3]*2 + 2*k3[3] + k4[3]))\n",
    "            derivs.append(1/6*(k1[4] + k2[4]*2 + 2*k3[4] + k4[4]))\n",
    "            derivx.append(1/6*(k1[5] + k2[5]*2 + 2*k3[5] + k4[5]))\n",
    "            q[i+1] = y1_t + h*derivq[-1]\n",
    "            v[i+1] = y2_t + h*derivv[-1]\n",
    "            p[i+1] = y3_t + h*derivp[-1]\n",
    "            s[i+1] = y4_t + h*derivs[-1]\n",
    "            f[i+1] = y5_t + h*derivf[-1]\n",
    "            X[i+1] = y6_t + h*derivx[-1]\n",
    "        else:\n",
    "            pds = dqdvdp(X[i],q[i], v[i], p[i], s[i], f[i], u[i],i)\n",
    "            predx = y1_t + h/24*(55*pds[5] - 59*derivx[-1] + 37*derivx[-2] - 9*derivx[-3])\n",
    "            predq = y1_t + h/24*(55*pds[0] - 59*derivq[-1] + 37*derivq[-2] - 9*derivq[-3])\n",
    "            predv = y2_t + h/24*(55*pds[1] - 59*derivv[-1] + 37*derivv[-2] - 9*derivv[-3])\n",
    "            predp = y3_t + h/24*(55*pds[2] - 59*derivp[-1] + 37*derivp[-2] - 9*derivp[-3])\n",
    "            predf = y5_t + h/24*(55*pds[3] - 59*derivf[-1] + 37*derivf[-2] - 9*derivf[-3])\n",
    "            preds = y4_t + h/24*(55*pds[4] - 59*derivs[-1] + 37*derivs[-2] - 9*derivs[-3])\n",
    "            cds = dqdvdp(predx,predq, predv, predp, preds, predf, u[i],i)\n",
    "            derivx.append(1/24*(9*cds[5] + 19*pds[5] - 5*derivx[-1] + derivx[-2]))\n",
    "            derivq.append(1/24*(9*cds[0] + 19*pds[0] - 5*derivq[-1] + derivq[-2]))\n",
    "            derivv.append(1/24*(9*cds[1] + 19*pds[1] - 5*derivv[-1] + derivv[-2]))\n",
    "            derivp.append(1/24*(9*cds[2] + 19*pds[2] - 5*derivp[-1] + derivp[-2]))\n",
    "            derivf.append(1/24*(9*cds[3] + 19*pds[3] - 5*derivf[-1] + derivf[-2]))\n",
    "            derivs.append(1/24*(9*cds[4] + 19*pds[4] - 5*derivs[-1] + derivs[-2]))\n",
    "            X[i+1] = y6_t + h*derivx[-1]\n",
    "            q[i+1] = y1_t + h*derivq[-1]\n",
    "            v[i+1] = y2_t + h*derivv[-1]\n",
    "            p[i+1] = y3_t + h*derivp[-1]\n",
    "            s[i+1] = y4_t + h*derivs[-1]\n",
    "            f[i+1] = y5_t + h*derivf[-1]\n",
    "    \n",
    "    # Standardize and low pass filter\n",
    "    qcons = (q-q.mean(0))/q.std(0)\n",
    "    pcons = (p-p.mean(0))/p.std(0)\n",
    "    b,a = signal.butter(3,.2/(fs/2), \"low\")\n",
    "    q = signal.filtfilt(b,a,qcons,axis=0)\n",
    "    p = signal.filtfilt(b,a,pcons,axis=0)\n",
    "    np.save(\"control{0:d}.npy\".format(kk),u)\n",
    "    np.save(\"qpure{0:d}.npy\".format(kk),qpure)\n",
    "    np.save(\"xpure{0:d}.npy\".format(kk),X)\n",
    "    return q    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 100 runs of the simulations\n",
    "Simuls = np.array(Parallel(n_jobs=100)(delayed(simulate)(k) for k in range(100)))\n",
    "np.save(\"Simuls\",Simuls)\n",
    "# Plot Stimuli and Simulations\n",
    "control = np.load(\"control0.npy\")\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(np.arange(Simuls.shape[1]-500)/100,Simuls[0,500:,:50])\n",
    "plt.title(\"Population 1\")\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(np.arange(Simuls.shape[1]-500)/100,Simuls[0,500:,50:])\n",
    "plt.title(\"Population 2\")\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(np.arange(Simuls.shape[1]-500)/100,control[500:])\n",
    "plt.title(\"Stimuli\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.savefig(\"SimulPlots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for running Analysis\n",
    "from sklearn.decomposition import PCA\n",
    "from nilearn.glm.first_level import glover_hrf\n",
    "import scipy.signal as signal\n",
    "import scipy.linalg as la\n",
    "import vgpccmbatch as gp\n",
    "from torch.multiprocessing import Pool\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform deconvolution and get show manifolds\n",
    "def genManifs(i,j):\n",
    "    # Downsample to rate of TR=2.5s to make similar to conventional fMRI acquisitions\n",
    "    Pop = simuls[i,500::250,:]\n",
    "    Popn = np.zeros((Pop.shape[0]*13,Pop.shape[1]))\n",
    "    # UpSample to 5Hz before deconvolution\n",
    "    Popn[::13] = Pop\n",
    "    b,a = signal.butter(3,1/13,'low')\n",
    "    Pop = signal.filtfilt(b,a,Popn)\n",
    "    PPI = np.load(\"control{0:d}.npy\".format(i))[500::250]\n",
    "    PPIn = np.zeros(len(PPI)*13)\n",
    "    PPIn[::13] = PPI\n",
    "    PPIn = np.convolve(np.ones(13),PPIn)\n",
    "    PPI = PPIn[:len(PPI)*13]\n",
    "    # Parse which condition we want to test\n",
    "    if j == 0:\n",
    "        PPI = 2*((PPI > 0).astype(float)-.5)\n",
    "    else:\n",
    "        PPI = 2*((PPI < 0).astype(float)-.5)\n",
    "    # Standardize signal\n",
    "    PPI = (PPI - PPI.mean())/PPI.std()\n",
    "    # Fourier Bases\n",
    "    hrf = glover_hrf(1*2.5/13,1,50) # HRF    \n",
    "    bases = [np.ones(len(PPI))] + [np.sin(2*np.pi*(i+1)*np.arange(len(PPI))/len(PPI)) for i in range(1,480)]\n",
    "    bases += [np.cos(2*np.pi*(i+1)*np.arange(len(PPI))/len(PPI)) for i in range(1,480)]\n",
    "    bases = np.array(bases).T\n",
    "    # Convolution matrix\n",
    "    cm = la.convolution_matrix(hrf,len(PPI))\n",
    "    basescm = cm[:len(PPI)].dot(bases)\n",
    "    # Inverting to get Fourier bases coefficients\n",
    "    B = np.linalg.inv(basescm.T.dot(basescm)).dot(basescm.T).dot(Popn)\n",
    "    X = bases.dot(B) # Deconvolved signal\n",
    "    PPI = (X.T*PPI).T # PPI\n",
    "    PPI = (PPI - PPI.mean(0))/PPI.std(0)\n",
    "    PI = X\n",
    "    PI = (PI - PI.mean(0))/PI.std(0) # Deconvolved BOLD\n",
    "    Pop1 = PI[::5,50:].T # System 1\n",
    "    Pop2 = PI[::5,:50].T # System 2\n",
    "    um = PCA()\n",
    "    um2 = PCA()\n",
    "    PPIr = PPI[:,50:].T # System 1\n",
    "    PPIl = PPI[:,:50].T # System 2\n",
    "    # Dimensionality Reduction    \n",
    "    um.fit(Pop1.T)\n",
    "    um2.fit(Pop2.T)\n",
    "    PPIr1 = um.transform(PPIr.T).T[[0]]\n",
    "    PPIl2 = um2.transform(PPIl.T).T[[0]]\n",
    "    m1 = um.transform(Pop1.T).T[[0]]\n",
    "    m2 = um2.transform(Pop2.T).T[[0]]\n",
    "    return PPIr1, PPIl2, m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP Testing Function, return a posteriori covariance\n",
    "def test(dat,cuda):\n",
    "    GP = gp.GP()\n",
    "    return GP.testCoupling(dat[0], dat[1][None,:], dat[2],5, tau=2, cuda=cuda)[1]\n",
    "\n",
    "def boot(dat):\n",
    "    pvals = []\n",
    "    ress = []\n",
    "    j = dat[0]\n",
    "    # Which GPU to use in multiprocessing\n",
    "    cuda = (mp.current_process()._identity[0] - 1)%8\n",
    "    for i in range(2):\n",
    "        PPIr1 = dat[1][i]\n",
    "        PPIl2 = dat[2][i]\n",
    "        m1 = dat[3][i]\n",
    "        m2 = dat[4][i]\n",
    "\n",
    "        args = [[PPIr1, PPIl2, m1],[PPIl2, PPIr1, m2]]\n",
    "        ret = []\n",
    "        # Test coupling\n",
    "        for k in range(len(args)):\n",
    "            ret+=[test(args[k],cuda)]\n",
    "        r = ret[0]\n",
    "        r2 = ret[1]\n",
    "        res = (r - r2).ravel()\n",
    "        pvals += [(res[0] > res[1:]).cpu().numpy().mean()]\n",
    "        ress += [np.array([r.cpu().numpy(),r2.cpu().numpy()])]#es.cpu().numpy()]\n",
    "    print(pvals,j)\n",
    "    # Return results\n",
    "    return np.array(pvals), np.array(ress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some noise to the simulations\n",
    "simuls = Simuls + .1*np.random.randn(*simuls.shape)\n",
    "PPIr1s PPIl2s, m1s, m2s = zip(*Parallel(n_jobs=250)(delayed(genManifs)(i,j) for i in range(100) for j in range(2)))\n",
    "print(\"Got Manifs!\")\n",
    "# Reshape it\n",
    "PPIr1s = np.array(PPIr1s).reshape(100,2,1,-1)\n",
    "PPIl2s = np.array(PPIl2s).reshape(100,2,1,-1)\n",
    "m1s = np.array(m1s).reshape(100,2,1,-1)\n",
    "m2s = np.array(m2s).reshape(100,2,1,-1)\n",
    "resss = [] # Results\n",
    "pvalss = [] # Pvals\n",
    "\n",
    "mp.set_start_method('spawn',force=True)\n",
    "with Pool(8) as p:\n",
    "    args = [[i,PPIr1s[i],PPIl2s[i],m1s[i],m2s[i]] for i in range(100)]\n",
    "    for i in range(10):\n",
    "        # Run the CCM analysis 10 times to account for RNG in the initialization of the\n",
    "        # Coupling measure algorithm\n",
    "        pvals, ress = zip(*p.map(boot,args))\n",
    "        pvalss += [pvals]\n",
    "        resss += [ress]\n",
    "        np.save(\"PvalsPPIdeconv.npy\", np.array(pvalss).reshape(i+1,100,2))\n",
    "        np.save(\"ResPPIdeconv.npy\", np.array(resss).reshape(i+1,100,2,2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res = np.median(np.load(\"ResPPIdeconv.npy\"),0)\n",
    "R = ((Res[:,:,0] - Res[:,:,1])).reshape(*Res.shape[:2],-1)\n",
    "\n",
    "# Results will be 2 numbers \n",
    "#(% Condition 1 Coupling, % Condition 2 Coupling)\n",
    "# This tests alternate hypothesis System 2 -> System 1\n",
    "((R[...,[0]] > R[...,1:]).mean(-1) < 0.05).sum(0)/100\n",
    "#array([0,  .36])\n",
    "# This test's alternate hypothesis System 1 -> System 2\n",
    "(1-(R[...,[0]] > R[...,1:]).mean(-1) < 0.05).sum(0)/100\n",
    "#array([.32,  .01])\n",
    "\n",
    "# If we change alpha, we see that we gain more statistical power while not sacrificing much specificity.\n",
    "# Say we change it to 0.35:\n",
    "((R[...,[0]] > R[...,1:]).mean(-1) < 0.35).sum(0)/100\n",
    "# array([0.05, 0.91])\n",
    "(1-(R[...,[0]] > R[...,1:]).mean(-1) < 0.35).sum(0)/100\n",
    "#array([0.8 , 0.05])\n",
    "# See, specificity is still 95%, very good, but we increase sensitivity exceptionally, up to at least 80%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
